{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ofornes/Work/GRECO/JASPAR-profile-inference',\n",
       " '/home/ofornes/Work/GRECO',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python37.zip',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python3.7',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python3.7/site-packages',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/ofornes/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append JASPAR-profile-inference to path\n",
    "jaspar_dir = os.path.abspath(\"./JASPAR-profile-inference\")\n",
    "sys.path.insert(0, jaspar_dir)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from JASPAR-profile-inference\n",
    "from __init__ import Jglobals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Class       #\n",
    "#-------------#\n",
    "\n",
    "class TF(object):\n",
    "\n",
    "    def __init__(self, gene_name, species):\n",
    "\n",
    "        self.gene_name = gene_name\n",
    "        self.species = species\n",
    "        self.uniacc = None\n",
    "        self.unientry = None\n",
    "        self.status = None\n",
    "        self.sequence = None\n",
    "        self.family = \"Unknown\"\n",
    "        self.cluster_num = None\n",
    "        # self.orthodb = set()\n",
    "        self.jaspar_id = None\n",
    "        self.hocomoco_id = set()\n",
    "        \n",
    "        # In vivo\n",
    "        self.chip_atlas = set()\n",
    "        self.cistromedb = set()\n",
    "        self.gtrd = set()\n",
    "        self.dap_seq = set()\n",
    "        self.remap = set()\n",
    "\n",
    "        # In vitro\n",
    "        self.ht_selex = set()\n",
    "        self.cisbp = set()\n",
    "        self.uniprobe = set()\n",
    "        self.smile_seq = set()\n",
    "\n",
    "        # Hidden variables (for internal use only)\n",
    "        self._uniaccs = set()\n",
    "        self._unientries = set()\n",
    "        self._sequences = set()\n",
    "\n",
    "    @property\n",
    "    def invivo(self):\n",
    "        \"\"\"\n",
    "        Returns 1 if the TF has been profiled by in vivo methods,\n",
    "        or 0 otherwise.\n",
    "        @rtype = {int}\n",
    "        \"\"\"\n",
    "\n",
    "        # For simplicity, ChIP-seq ~ ChIP-exo ~ DAP-seq\n",
    "        if self.chip_atlas or self.cistromedb or self.gtrd or self.dap_seq or self.remap:\n",
    "            return(1)\n",
    "\n",
    "        return(0)\n",
    "\n",
    "    @property\n",
    "    def invitro(self):\n",
    "        \"\"\"\n",
    "        Returns the number of different experimental methods by\n",
    "        which a TF has been profiled in vitro.\n",
    "        @rtype = {int}\n",
    "        \"\"\"\n",
    "\n",
    "        n = 0\n",
    "\n",
    "        if self.ht_selex:\n",
    "            n += 1\n",
    "        # i.e. PBM\n",
    "        if self.cisbp or self.uniprobe:\n",
    "            n += 1\n",
    "        if self.smile_seq:\n",
    "            n += 1\n",
    "\n",
    "        return(n)\n",
    "\n",
    "    @property\n",
    "    def evidence(self):\n",
    "        \"\"\"\n",
    "        Returns the amount of evidence associated with a TF.\n",
    "        @rtype = {int}\n",
    "        \"\"\"\n",
    "        return(self.invivo+self.invitro)\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        string = \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "            self.gene_name,\n",
    "            self.species,\n",
    "            self.uniacc,\n",
    "            # \";\".join(sorted([i for i in self._uniaccs if i != self.uniacc])),\n",
    "            self.unientry,\n",
    "            # \";\".join(sorted([i for i in self._unientries if i != self.unientry])),\n",
    "            self.status,\n",
    "            self.sequence,\n",
    "            # \";\".join(sorted([i for i in self._sequences if i != self.sequence])),\n",
    "            self.family,\n",
    "            self.cluster_num,\n",
    "            self.evidence,\n",
    "            # \";\".join(sorted([i for i in self._pfam_ids if i != self.pfam_id])),\n",
    "            # \";\".join(sorted(self.orthodb)),\n",
    "            self.jaspar_id,\n",
    "            \";\".join(sorted(self.hocomoco_id)),\n",
    "            \";\".join(sorted(self.chip_atlas)),\n",
    "            \";\".join(sorted(self.cistromedb)),\n",
    "            \";\".join(sorted(self.gtrd)),\n",
    "            \";\".join(sorted(self.remap)),\n",
    "            \";\".join(sorted(self.dap_seq)),\n",
    "            \";\".join(sorted(self.ht_selex)),\n",
    "            \";\".join(sorted(self.cisbp)),\n",
    "            \";\".join(sorted(self.uniprobe)),\n",
    "            \";\".join(sorted(self.smile_seq))\n",
    "        )\n",
    "\n",
    "        return(string)\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        string = \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "            self.gene_name,\n",
    "            self.species,\n",
    "            self.uniacc,\n",
    "            # \";\".join(sorted([i for i in self._uniaccs if i != self.uniacc])),\n",
    "            self.unientry,\n",
    "            # \";\".join(sorted([i for i in self._unientries if i != self.unientry])),\n",
    "            self.status,\n",
    "            self.sequence,\n",
    "            # \";\".join(sorted([i for i in self._sequences if i != self.sequence])),\n",
    "            self.family,\n",
    "            self.cluster_num,\n",
    "            self.evidence,\n",
    "            # \";\".join(sorted([i for i in self._pfam_ids if i != self.pfam_id])),\n",
    "            # \";\".join(sorted(self.orthodb)),\n",
    "            self.jaspar_id,\n",
    "            \";\".join(sorted(self.hocomoco_id)),\n",
    "            \";\".join(sorted(self.chip_atlas)),\n",
    "            \";\".join(sorted(self.cistromedb)),\n",
    "            \";\".join(sorted(self.gtrd)),\n",
    "            \";\".join(sorted(self.remap)),\n",
    "            \";\".join(sorted(self.dap_seq)),\n",
    "            \";\".join(sorted(self.ht_selex)),\n",
    "            \";\".join(sorted(self.cisbp)),\n",
    "            \";\".join(sorted(self.uniprobe)),\n",
    "            \";\".join(sorted(self.smile_seq))\n",
    "        )\n",
    "\n",
    "        return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Paths       #\n",
    "#-------------#\n",
    "\n",
    "hocomoco_file = \"./Data/Databases/HOCOMOCO/HOCOMOCOv11_full_jaspar_format.txt\"\n",
    "chip_atlas_file = \"./Data/Experiments/ChIP-seq.ChIP-Atlas.tsv\"\n",
    "cistromedb_file = \"./Data/Experiments/ChIP-seq.CistromeDB.tsv\"\n",
    "gtrd_file = \"./Data/Experiments/ChIP-seq.GTRD.tsv\"\n",
    "remap_file = \"./Data/Experiments/ChIP-seq.ReMap2020.tsv\"\n",
    "dap_seq_file = \"./Data/Experiments/DAP-seq.PMID:27203113.tsv\"\n",
    "ht_selex_files = [\"./Data/Experiments/HT-SELEX.PMID:23332764.tsv\",\n",
    "                  \"./Data/Experiments/HT-SELEX.PMID:28473536.tsv\"]\n",
    "cisbp_txt_file = \"./Data/Databases/CisBP-2.0/PWMs.txt\"\n",
    "cisbp_tsv_file = \"./Data/Experiments/PBM.CisBP-2.0.tsv\"\n",
    "uniprobe_file = \"./Data/Experiments/PBM.UniPROBE.tsv\"\n",
    "smile_seq = \"./Data/Experiments/SMiLE-seq.PMID:28092692.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBD8\tArabidopsis thaliana\tQ9LME6\tMBD8_ARATH\tReviewed\tMDDGDLGNNHHNFLGGAGNRLSAESLPLIDTRLLSQSELRALSQCSSLSPSSSASLAASAGGDDDLTPKIDRSVFNESAGSRKQTFLRLRLARHPQPPEEPPSPQRQRDDSSREEQTQVASLLRSLFNVDSNQSKEEEDEGEEELEDNEGQIHYNSYVYQRPNLDSIQNVLIQGTSGNKIKRKRGRPRKIRNPSEENEVLDLTGEASTYVFVDKTSSNLGMVSRVGSSGISLDSNSVKRKRGRPPKNKEEIMNLEKRDSAIVNISAFDKEELVVNLENREGTIVDLSALASVSEDPYEEELRRITVGLKTKEEILGFLEQLNGEWVNIGKKKKVVNACDYGGYLPRGWRLMLYIKRKGSNLLLACRRYISPDGQQFETCKEVSTYLRSLLESPSKNQHYYLQSDNKTLGQQPVIANESLLGNSDSMDSETMQYLESGRTSSEVFEEAKAVENGNEADRVKTSLMQKDDNADFLNGVEDNDDDMKKRDGNMENLATLSNSEMTKSLPTTTNELQQYFSSQINRVQ\tAT hook,MBD\tNone\t0\tnan\t\t\t\t\t\t\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "#-------------#\n",
    "# Parse Data  #\n",
    "#-------------#\n",
    "\n",
    "# Initialize\n",
    "tfs = set()\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(\"./Data/Parsed/TFs.tab.gz\"):\n",
    "\n",
    "    # Initialize\n",
    "    tf = TF(line[0], line[1])\n",
    "\n",
    "    # Get UniProt Accession\n",
    "    uniaccs = line[2].split(\";\")\n",
    "    tf.uniacc = uniaccs[0]\n",
    "    tf._uniaccs.update(set(uniaccs))\n",
    "\n",
    "    # Get UniProt Entry\n",
    "    unientries = line[3].split(\";\")\n",
    "    tf.unientry = unientries[0]\n",
    "    tf._unientries.update(set(unientries))\n",
    "\n",
    "    # Get sequence\n",
    "    sequences = line[4].split(\";\")\n",
    "    tf.sequence = sequences[0]\n",
    "    tf._sequences.update(set(sequences))\n",
    "\n",
    "    # Get status (i.e. reviewed or not)\n",
    "    tf.status = line[5]\n",
    "\n",
    "    # Get family\n",
    "    tf.family = line[6]\n",
    "\n",
    "    # Get JASPAR ids\n",
    "    tf.jaspar_id = line[7]\n",
    "\n",
    "    # # Get orthoDB cluster\n",
    "    # codec = coreapi.codecs.CoreJSONCodec()\n",
    "    # for uniacc in tf._uniaccs:\n",
    "    #     json_file = os.path.join(args.orthodb, \"%s.json\" % uniacc)\n",
    "    #     if not os.path.exists(json_file):\n",
    "    #         client = coreapi.Client()\n",
    "    #         response = client.get(\n",
    "    #             \"https://www.orthodb.org/search?query=%s&level=2759&species=2759\" % uniacc)\n",
    "    #         json_obj = json.loads(codec.encode(response))\n",
    "    #         with open(json_file, \"w\") as j:\n",
    "    #             j.write(json.dumps(json_obj, sort_keys=True, indent=4, separators=(\",\", \": \")))\n",
    "    #     with open(json_file, \"r\") as j:  \n",
    "    #         json_obj = json.load(j)\n",
    "    #         for orthodb in json_obj[\"data\"]:\n",
    "    #             tf.orthodb.add(orthodb)\n",
    "\n",
    "    # Add TF to TFs\n",
    "    tfs.add(tf)\n",
    "\n",
    "print(next(iter(tfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# HOCOMOCO    #\n",
    "#-------------#\n",
    "\n",
    "#  678 Homo sapiens\n",
    "#  451 Mus musculus\n",
    "\n",
    "# SMCA5_MOUSE # Not a TF: SWI/SNF-related matrix-associated actin-dependent regulator of chromatin subfamily A member 5\n",
    "# FUBP1_MOUSE # Not a TF: Far upstream element-binding protein 1\n",
    "# BRCA1_MOUSE # Not a TF: Breast cancer type 1 susceptibility protein homolog\n",
    "# EVI1_MOUSE  # Not a TF: Histone-lysine N-methyltransferase MECOM\n",
    "# TAF1_MOUSE  # Not a TF: Transcription initiation factor TFIID subunit 1\n",
    "# BRAC_MOUSE  # Not a valid UniProt Entry\n",
    "# HLTF_MOUSE  # Not a TF: Helicase-like transcription factor\n",
    "# TAF1_HUMAN  # Not a TF: Transcription initiation factor TFIID subunit 1\n",
    "# HLTF_HUMAN  # Not a TF: Helicase-like transcription factor\n",
    "# BRCA1_HUMAN # Not a TF: Breast cancer type 1 susceptibility protein\n",
    "# SMCA5_HUMAN # Not a TF: SWI/SNF-related matrix-associated actin-dependent regulator of chromatin subfamily A member 5\n",
    "# ZF64A_HUMAN # Not a valid UniProt Entry\n",
    "# BRAC_HUMAN  # Not a valid UniProt Entry\n",
    "# EVI1_HUMAN  # Not a TF: Histone-lysine N-methyltransferase MECOM\n",
    "# FUBP1_HUMAN # Not a TF: Far upstream element-binding protein 1\n",
    "# BPTF_HUMAN  # Not a TF: Nucleosome-remodeling factor subunit BPTF\n",
    "# CENPB_HUMAN # Not a TF: Major centromere autoantigen B\n",
    "# ZBT48_HUMAN # Not a valid UniProt Entry; should be TZAP_HUMAN\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_file(hocomoco_file):\n",
    "\n",
    "    if line.startswith(\">\"):\n",
    "\n",
    "        # Get unientry\n",
    "        m = re.search(\"(\\w+_(HUMAN|MOUSE))\", line)\n",
    "        unientry = m.group(1)\n",
    "\n",
    "        # For each TF...\n",
    "        for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "            if unientry in tf._unientries:\n",
    "                tf.hocomoco_id.add(line[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHR {'AHR_HUMAN.H11MO.0.B'}\n",
      "AIRE {'AIRE_HUMAN.H11MO.0.C'}\n",
      "ALX1 {'ALX1_HUMAN.H11MO.0.B'}\n",
      "ALX3 {'ALX3_HUMAN.H11MO.0.D'}\n",
      "ALX4 {'ALX4_HUMAN.H11MO.0.D'}\n",
      "AR {'ANDR_HUMAN.H11MO.1.A', 'ANDR_HUMAN.H11MO.0.A', 'ANDR_HUMAN.H11MO.2.A'}\n",
      "ARID3A {'ARI3A_HUMAN.H11MO.0.D'}\n",
      "ARID5B {'ARI5B_HUMAN.H11MO.0.C'}\n",
      "ARNT {'ARNT_HUMAN.H11MO.0.B'}\n",
      "ARNT2 {'ARNT2_HUMAN.H11MO.0.D'}\n",
      "...\n",
      "//\n",
      "Total genes: 1057\n",
      "Total feats: 1214\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.hocomoco_id)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.hocomoco_id)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# GTRD        #\n",
    "#-------------#\n",
    "\n",
    "#   71 Arabidopsis thaliana\n",
    "#  213 Caenorhabditis elegans\n",
    "#   11 Danio rerio\n",
    "#  249 Drosophila melanogaster\n",
    "# 1236 Homo sapiens\n",
    "#  513 Mus musculus\n",
    "#   12 Rattus norvegicus\n",
    "#  137 Saccharomyces cerevisiae\n",
    "#   32 Schizosaccharomyces pombe\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(gtrd_file):\n",
    "\n",
    "    # Inialize\n",
    "    experiment_id = line[0]\n",
    "    uniacc = line[1]\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "        if uniacc in tf._uniaccs:\n",
    "            tf.gtrd.add(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11723 {'EXP043557'}\n",
      "ABF4 {'EXP041418'}\n",
      "ADD1 {'EXP044073'}\n",
      "ADNP {'EXP039553'}\n",
      "AEBP2 {'EXP040109'}\n",
      "AGL8 {'EXP040838'}\n",
      "AP1 {'EXP041282'}\n",
      "AR {'EXP040660', 'EXP038106', 'EXP040661', 'EXP037067', 'EXP038636', 'EXP038193', 'EXP038192', 'EXP038188', 'EXP036887', 'EXP040665', 'EXP038191', 'EXP037263', 'EXP038189'}\n",
      "ARF6 {'EXP041307'}\n",
      "ARID2 {'EXP040161'}\n",
      "...\n",
      "//\n",
      "Total genes: 814\n",
      "Total feats: 1958\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.gtrd)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.gtrd)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# DAP-seq     #\n",
    "#-------------#\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(dap_seq_file):\n",
    "\n",
    "    if line[0] == \"AvgSpotLen\":\n",
    "        continue\n",
    "\n",
    "    species = line[8]\n",
    "    sra_run = line[9]\n",
    "    gene = line[15]\n",
    "\n",
    "    if line[8] not in species:\n",
    "        continue\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "        if gene.upper() in tf.gene_name.upper():\n",
    "            tf.dap_seq.add(sra_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABF2 {'SRR2926839'}\n",
      "ABF2 {'SRR2926839'}\n",
      "ABI5 {'SRR2926841', 'SRR2926840'}\n",
      "ABR1 {'SRR2926082', 'SRR2926081'}\n",
      "AGL13 {'SRR2926463'}\n",
      "AGL15 {'SRR2926465', 'SRR2926464'}\n",
      "AGL16 {'SRR2926466', 'SRR2926467'}\n",
      "AGL42 {'SRR2926470'}\n",
      "AGL6 {'SRR2926472'}\n",
      "AGL61 {'SRR2926472'}\n",
      "...\n",
      "//\n",
      "Total genes: 474\n",
      "Total feats: 911\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.dap_seq)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.dap_seq)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# HT-SELEX    #\n",
    "#-------------#\n",
    "\n",
    "# For each file...\n",
    "for file_name in ht_selex_files:\n",
    "\n",
    "    m = re.search(\"HT-SELEX.PMID:(\\d+).tsv\", file_name)\n",
    "    pmid = int(m.group(1))\n",
    "\n",
    "    # For each line...\n",
    "    for line in Jglobals.parse_tsv_file(file_name):\n",
    "\n",
    "        if line[0] == \"Alias\":\n",
    "            continue\n",
    "\n",
    "        m = re.search(\"^([A-Za-z\\d]+)_\", line[0])\n",
    "        if m:\n",
    "\n",
    "            gene_name = m.group(1)\n",
    "\n",
    "            if pmid == 23332764:\n",
    "                sra_run = line[14]\n",
    "            else:\n",
    "                sra_run = line[19]\n",
    "\n",
    "            # For each TF...\n",
    "            for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "                # HT-SELEX data only available for human and mouse\n",
    "                if tf.species not in [\"Homo sapiens\", \"Mus musculus\"]:\n",
    "                    continue\n",
    "                if tf.gene_name == gene_name:\n",
    "                    tf.ht_selex.add(sra_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALX1 {'ERR1002055', 'ERR1002057', 'ERR1002056', 'ERR1002052', 'ERR1002050', 'ERR1002051', 'ERR1002054', 'ERR1002053'}\n",
      "ALX3 {'ERR1002067', 'ERR195527', 'ERR1002064', 'ERR195526', 'ERR1002060', 'ERR193773', 'ERR1002058', 'ERR193770', 'ERR1010299', 'ERR195525', 'ERR1002073', 'ERR195528', 'ERR1002065', 'ERR1002072', 'ERR193772', 'ERR1002062', 'ERR1011404', 'ERR1002069', 'ERR1002066', 'ERR1002061', 'ERR1002068', 'ERR1011038', 'ERR1002059', 'ERR1002070', 'ERR1010665', 'ERR193771', 'ERR1002071', 'ERR1002063'}\n",
      "ALX4 {'ERR194917', 'ERR1002074', 'ERR1002077', 'ERR194918', 'ERR194919', 'ERR1002076', 'ERR1002078', 'ERR1002079', 'ERR194920', 'ERR1002080', 'ERR1002081', 'ERR1002075'}\n",
      "AR {'ERR193681', 'ERR193972', 'ERR193680', 'ERR193679', 'ERR193678', 'ERR193971', 'ERR193970', 'ERR193973'}\n",
      "ARGFX {'ERR1002087', 'ERR1002085', 'ERR1002082', 'ERR1002089', 'ERR1002083', 'ERR1002088', 'ERR1002084', 'ERR1002086'}\n",
      "ARNT2 {'ERR1002094', 'ERR1002091', 'ERR1002090', 'ERR1011039', 'ERR1002097', 'ERR1002092', 'ERR1010300', 'ERR1002095', 'ERR1010666', 'ERR1011405', 'ERR1002093', 'ERR1002096'}\n",
      "ARNTL {'ERR1002099', 'ERR1002104', 'ERR194921', 'ERR1011406', 'ERR1002098', 'ERR1010667', 'ERR194924', 'ERR1002102', 'ERR1010301', 'ERR1011040', 'ERR1002100', 'ERR194922', 'ERR194923', 'ERR1002105', 'ERR1002101', 'ERR1002103'}\n",
      "ARX {'ERR195532', 'ERR1002107', 'ERR1002112', 'ERR1002108', 'ERR195530', 'ERR1002110', 'ERR1002106', 'ERR1002109', 'ERR195529', 'ERR1002113', 'ERR1002111', 'ERR195531'}\n",
      "ASCL1 {'ERR1002120', 'ERR1002117', 'ERR1894980', 'ERR1002114', 'ERR1894981', 'ERR1002119', 'ERR1002116', 'ERR1002121', 'ERR1894976', 'ERR1894978', 'ERR1894982', 'ERR1894983', 'ERR1894977', 'ERR1002118', 'ERR1002115', 'ERR1894979'}\n",
      "ASCL2 {'ERR1002127', 'ERR1002135', 'ERR1002123', 'ERR1002133', 'ERR1002124', 'ERR1002137', 'ERR1002122', 'ERR1002134', 'ERR1002129', 'ERR1002136', 'ERR1002130', 'ERR1002128', 'ERR1002125', 'ERR1002131', 'ERR1002126', 'ERR1002132'}\n",
      "...\n",
      "//\n",
      "Total genes: 673\n",
      "Total feats: 9462\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.ht_selex)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.ht_selex)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# CIS-BP      #\n",
    "#-------------#\n",
    "\n",
    "valid_matrix_ids = set()\n",
    "\n",
    "# Get valid PWMs\n",
    "for matrix_id in Jglobals.parse_file(cisbp_txt_file):\n",
    "    valid_matrix_ids.add(matrix_id)\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_file(cisbp_tsv_file):\n",
    "\n",
    "    matrix_ids = re.findall(\"(M\\d{5}_2.00)\", line)\n",
    "\n",
    "    if matrix_ids:\n",
    "\n",
    "        line = line.strip(\"\\n\").split(\"\\t\")\n",
    "        gene_name = line[1]\n",
    "        species = line[2].replace(\"_\", \" \")\n",
    "\n",
    "        # Skip inferred TFs\n",
    "        if line[3] != \"D\":\n",
    "            continue\n",
    "\n",
    "        # For each TF...\n",
    "        for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "            if tf.gene_name.upper() == gene_name.upper() and species == tf.species:\n",
    "                tf.cisbp.update(valid_matrix_ids.intersection(set(matrix_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABF1 {'M00001_2.00', 'M00902_2.00'}\n",
      "ABF1 {'M01773_2.00', 'M01772_2.00'}\n",
      "ABF2 {'M01771_2.00'}\n",
      "ABF2 {'M00069_2.00'}\n",
      "ABF3 {'M01782_2.00'}\n",
      "ABF4 {'M01056_2.00', 'M01057_2.00'}\n",
      "ABI5 {'M01776_2.00'}\n",
      "ABR1 {'M01051_2.00'}\n",
      "ACE2 {'M00033_2.00'}\n",
      "ADR1 {'M00021_2.00'}\n",
      "...\n",
      "//\n",
      "Total genes: 1199\n",
      "Total feats: 1541\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.cisbp)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.cisbp)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# UniPROBE    #\n",
    "#-------------#\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(uniprobe_file):\n",
    "   \n",
    "    if line[0] == \"Protein\":\n",
    "        continue\n",
    "\n",
    "    gene_name = line[0]\n",
    "    uniprobe_id = line[1]\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "        if tf.gene_name.upper() == gene_name.upper() and line[2] == tf.species:\n",
    "            tf.uniprobe.add(uniprobe_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABF1 {'UP00452'}\n",
      "AFT1 {'UP00344'}\n",
      "ARO80 {'UP00329'}\n",
      "ARX {'UP00584'}\n",
      "ASG1 {'UP00350'}\n",
      "Abd-B {'UP00503'}\n",
      "Ahctf1 {'UP01352'}\n",
      "Alx3 {'UP00108'}\n",
      "Alx4 {'UP00187'}\n",
      "Ar {'UP01353'}\n",
      "...\n",
      "//\n",
      "Total genes: 540\n",
      "Total feats: 558\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.uniprobe)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.uniprobe)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# SMiLE-seq   #\n",
    "#-------------#\n",
    "\n",
    "synonyms = {\n",
    "    \"CEBPb\": \"CEBPB\",\n",
    "    \"cFOS\": \"FOS\",\n",
    "    \"cFOSL2\": \"FOSL2\",\n",
    "    \"cJUN\": \"JUN\",\n",
    "    \"PPARa\": \"PPARA\",\n",
    "    \"PPARg\": \"PPARG\",\n",
    "    \"RXRa\": \"RXRA\",\n",
    "    \"RXRg\": \"RXRG\"            \n",
    "}\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(smile_seq):\n",
    "\n",
    "    if line[0] == \"Assay_Type\":\n",
    "        continue\n",
    "\n",
    "    sra_run = line[13]\n",
    "\n",
    "    for gene_name in line[16].split(\"_\")[0].split(\"-\"):\n",
    "        if gene_name in synonyms:\n",
    "            gene_name = synonyms[gene_name]\n",
    "\n",
    "        # For each TF...\n",
    "        for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "            if tf.gene_name.upper() == gene_name.upper() and line[12] == tf.species:\n",
    "                tf.smile_seq.add(sra_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARNTL {'SRR3405116', 'SRR3405117'}\n",
      "CEBPB {'SRR3405054'}\n",
      "CLOCK {'SRR3405116', 'SRR3405117'}\n",
      "CTCF {'SRR3405066', 'SRR3405055', 'SRR3405078'}\n",
      "EN1 {'SRR3405089'}\n",
      "Egr1 {'SRR3402436'}\n",
      "FLI1 {'SRR3405101'}\n",
      "FOS {'SRR3405132', 'SRR3405143', 'SRR3405133', 'SRR3405150', 'SRR3405142'}\n",
      "FOSB {'SRR3405134', 'SRR3405144', 'SRR3405151', 'SRR3405145'}\n",
      "FOSL1 {'SRR3405152', 'SRR3405136', 'SRR3405146'}\n",
      "...\n",
      "//\n",
      "Total genes: 70\n",
      "Total feats: 151\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.smile_seq)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.smile_seq)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUN Homo sapiens 4 1 3\n",
      "PAX7 Homo sapiens 4 1 3\n",
      "MAX Homo sapiens 4 1 3\n",
      "Rxra Mus musculus 4 1 3\n",
      "FOS Homo sapiens 4 1 3\n",
      "JUNB Homo sapiens 3 1 2\n",
      "JUND Homo sapiens 3 1 2\n",
      "KLF11 Homo sapiens 3 1 2\n",
      "LEF1 Homo sapiens 3 1 2\n",
      "FOXP1 Homo sapiens 3 1 2\n",
      "...\n",
      "//\n",
      "Homo sapiens 34\n",
      "Mus musculus 9\n"
     ]
    }
   ],
   "source": [
    "#-------------#\n",
    "# Triples     #\n",
    "#-------------#\n",
    "count = 0\n",
    "evidence = {}\n",
    "for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "    if tf.invivo > 0 and tf.invitro > 1:\n",
    "        evidence.setdefault(tf.species, 0)\n",
    "        evidence[tf.species] += 1\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.species, tf.evidence, tf.invivo, tf.invitro)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "for species in sorted(evidence):\n",
    "    print(species, evidence[species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUN Homo sapiens 4 1 3\n",
      "PAX7 Homo sapiens 4 1 3\n",
      "MAX Homo sapiens 4 1 3\n",
      "Rxra Mus musculus 4 1 3\n",
      "FOS Homo sapiens 4 1 3\n",
      "JUNB Homo sapiens 3 1 2\n",
      "JUND Homo sapiens 3 1 2\n",
      "KLF11 Homo sapiens 3 1 2\n",
      "LEF1 Homo sapiens 3 1 2\n",
      "FOXP1 Homo sapiens 3 1 2\n",
      "...\n",
      "//\n",
      "Arabidopsis thaliana 114\n",
      "Caenorhabditis elegans 26\n",
      "Drosophila melanogaster 28\n",
      "Homo sapiens 214\n",
      "Mus musculus 58\n",
      "Saccharomyces cerevisiae 15\n"
     ]
    }
   ],
   "source": [
    "#-------------#\n",
    "# Duos        #\n",
    "#-------------#\n",
    "count = 0\n",
    "evidence = {}\n",
    "for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "    if tf.invivo > 0 and tf.invitro > 0:\n",
    "        evidence.setdefault(tf.species, 0)\n",
    "        evidence[tf.species] += 1\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.species, tf.evidence, tf.invivo, tf.invitro)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "for species in sorted(evidence):\n",
    "    print(species, evidence[species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Pfam        #\n",
    "#-------------#\n",
    "\n",
    "# The following code is adapted from:\n",
    "# https://github.com/wassermanlab/JASPAR-profile-inference/blob/master/files/get_files.py\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "import json\n",
    "from infer_profile import hmmAlign, hmmScan, _makeSeqFile\n",
    "\n",
    "# Initialize\n",
    "seq_file = \".seq.fasta\"\n",
    "hmm_database = os.path.join(jaspar_dir, \"files\", \"pfam-DBDs\", \"all_DBDs.hmm\")\n",
    "\n",
    "# Change dir\n",
    "os.chdir(sys.path[1])\n",
    "os.chdir(os.path.abspath(\"./Data/Pfam/\"))\n",
    "\n",
    "# Skip if JSON file already exists\n",
    "json_file = \"TFs.json\"\n",
    "if not os.path.exists(json_file):\n",
    "\n",
    "    # Initialize\n",
    "    pfams = {}\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "\n",
    "        # Initialize\n",
    "        uniacc = tf.uniacc\n",
    "        pfams.setdefault(uniacc, [])\n",
    "\n",
    "        # Make seq file\n",
    "        seq = Seq(tf.sequence, IUPAC.protein)\n",
    "        seq_record = SeqRecord(seq, id=uniacc, name=uniacc, description=uniacc)\n",
    "        _makeSeqFile(seq_record, seq_file)\n",
    "\n",
    "        # For each DBD...\n",
    "        for pfam_ac, start, end, evalue in hmmScan(seq_file, hmm_database, non_overlapping_domains=True):\n",
    "\n",
    "            # Initialize\n",
    "            hmm_file = os.path.join(jaspar_dir, \"files\", \"pfam-DBDs\", \"%s.hmm\" % pfam_ac)\n",
    "\n",
    "            # Make seq file\n",
    "            sub_seq = seq[start:end]\n",
    "            seq_record = SeqRecord(sub_seq, id=uniacc, name=uniacc, description=uniacc)\n",
    "            _makeSeqFile(seq_record, seq_file)\n",
    "\n",
    "            # Add DBDs\n",
    "            alignment = hmmAlign(seq_file, hmm_file)\n",
    "            pfams[uniacc].append((pfam_ac, alignment, start+1, end, evalue))\n",
    "\n",
    "    # Write\n",
    "    Jglobals.write(json_file, json.dumps(pfams, sort_keys=True, indent=4, separators=(\",\", \": \")))\n",
    "\n",
    "    # Remove seq file\n",
    "    if os.path.exists(seq_file):\n",
    "        os.remove(seq_file)\n",
    "\n",
    "# Change dir back\n",
    "os.chdir(sys.path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G5ECU7']\n",
      "['G5ECU7']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'TFs.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c997db713a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;31m#Jglobals.write(json_file, json.dumps(clusters, sort_keys=True, indent=4, separators=(\",\", \": \")))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TFs.json'"
     ]
    }
   ],
   "source": [
    "#-------------#\n",
    "# Cluster     #\n",
    "#-------------#\n",
    "\n",
    "# The following code is adapted from:\n",
    "# https://github.com/wassermanlab/JASPAR-profile-inference/blob/master/finfer_profile.py\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from infer_profile import _filter_results_by_Rost, _get_pid\n",
    "\n",
    "def get_members(tf):\n",
    "\n",
    "    # Initialize\n",
    "    members = []\n",
    "    tf_DBDs = [dbd[0] for dbd in pfams[tf.uniacc]]\n",
    "    tf_alignments = [dbd[1] for dbd in pfams[tf.uniacc]]\n",
    "    seq = Seq(tf.sequence, IUPAC.protein)\n",
    "    seq_record = SeqRecord(seq, id=tf.uniacc, name=tf.uniacc, description=tf.uniacc)\n",
    "    fasta_file = os.path.join(clusters_dir, \"%s.fasta\" % species_dict[tf.species])\n",
    "\n",
    "    # Get cut-offs on the percentage of sequence identity\n",
    "    cutoffs = {}\n",
    "    for pfam_ac in pfam_cutoffs:\n",
    "        if pfam_cutoffs[pfam_ac][0] in tf_DBDs:\n",
    "            cutoffs.setdefault(pfam_cutoffs[pfam_ac][0], pfam_cutoffs[pfam_ac][1])\n",
    "\n",
    "    # BLAST+ search\n",
    "    blast_results = BLAST(seq_record, fasta_file)\n",
    "\n",
    "    # Filter results\n",
    "    for filtered_result in sorted(_filter_results_by_Rost(blast_results), key=lambda x: x[5], reverse=True):\n",
    "\n",
    "        if filtered_result[1] in clusters:\n",
    "            continue\n",
    "\n",
    "        # Both TFs have same DBD composition\n",
    "        if [dbd[0] for dbd in pfams[filtered_result[1]]] == tf_DBDs:\n",
    "\n",
    "            # Inference: percentage of sequence identity\n",
    "            pids = []\n",
    "            pid_cutoffs = []\n",
    "            alignments = [dbd[1] for dbd in pfams[filtered_result[1]]]\n",
    "            for a in range(len(alignments)):\n",
    "                pid_cutoffs.append(_get_pid(tf_alignments[a], alignments[a]))\n",
    "            if True in pid_cutoffs:\n",
    "                members.append(filtered_result[1])\n",
    "\n",
    "    print(members)\n",
    "    return(None)\n",
    "\n",
    "    return(members)\n",
    "\n",
    "def BLAST(seq_record, fasta_file):\n",
    "\n",
    "    # Initialize\n",
    "    blast_results = set()\n",
    "    outfmt = \"sseqid pident length qstart qend sstart send evalue bitscore ppos qlen slen\"\n",
    "\n",
    "    # Run BLAST+\n",
    "    cmd = \"blastp -db %s -outfmt \\\"6 %s\\\"\" % (fasta_file, outfmt)\n",
    "    process = subprocess.Popen([cmd], shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    fasta_sequence = \">%s\\n%s\" % (seq_record.id, seq_record.seq)\n",
    "    process.stdin.write(fasta_sequence.encode())\n",
    "    (blast_records, blast_errors) = process.communicate()\n",
    "\n",
    "    # For each BLAST+ record...\n",
    "    for blast_record in blast_records.decode(\"utf-8\").split(\"\\n\"):\n",
    "\n",
    "        # Custom BLAST+ record:\n",
    "        # (1) identifier of target sequence;\n",
    "        # (2) percentage of identical matches;\n",
    "        # (3) alignment length;\n",
    "        # (4-5, 6-7) start and end-position in query and in target;\n",
    "        # (8) E-value;\n",
    "        # (9) bit score;\n",
    "        # (10) percentage of positive-scoring matches; and\n",
    "        # (4-7, 11, 12) joint coverage (i.e. square root of the coverage\n",
    "        # on the query and the target).\n",
    "        blast_record = blast_record.split(\"\\t\")\n",
    "\n",
    "        # Skip if not a BLAST+ record\n",
    "        if len(blast_record) != 12: continue\n",
    "\n",
    "        # Get BLAST+ record\n",
    "        target_id = blast_record[0]\n",
    "        percent_identities = float(blast_record[1])\n",
    "        alignment_length = int(blast_record[2])\n",
    "        query_start_end = \"%s-%s\" % (blast_record[3], blast_record[4])\n",
    "        target_start_end = \"%s-%s\" % (blast_record[5], blast_record[6])\n",
    "        e_value = float(blast_record[7])\n",
    "        score = float(blast_record[8])\n",
    "        percent_similarity = float(blast_record[9])\n",
    "        query_aligned_residues = int(blast_record[4]) - int(blast_record[3]) + 1\n",
    "        query_length = float(blast_record[10])\n",
    "        target_aligned_residues = int(blast_record[6]) - int(blast_record[5]) + 1\n",
    "        target_length = float(blast_record[11])\n",
    "        query_coverage = query_aligned_residues * 100 / query_length\n",
    "        target_coverage = target_aligned_residues * 100 / target_length\n",
    "        joint_coverage = math.sqrt(query_coverage * target_coverage)\n",
    "\n",
    "        # Add BLAST+ record to search results\n",
    "        blast_results.add((seq_record.id, target_id, query_start_end, target_start_end, e_value, score, percent_identities, alignment_length, percent_similarity, joint_coverage))\n",
    "\n",
    "    # Return results sorted by score\n",
    "    return(list(sorted(blast_results, key=lambda x: x[-1], reverse=True)))\n",
    "\n",
    "# Initialize\n",
    "cluster = 0\n",
    "clusters = {}\n",
    "clusters_dir = \"./Data/Clusters/\"\n",
    "species_dict = {\n",
    "    \"Arabidopsis thaliana\": \"plants\",\n",
    "    \"Caenorhabditis elegans\": \"nematodes\",\n",
    "    \"Drosophila melanogaster\": \"insects\",\n",
    "    \"Homo sapiens\": \"vertebrates\",\n",
    "    \"Mus musculus\": \"vertebrates\",\n",
    "    \"Saccharomyces cerevisiae\": \"fungi\"\n",
    "}\n",
    "with open(\"./Data/Pfam/TFs.json\") as f:\n",
    "    pfams = json.load(f)\n",
    "with open(os.path.join(jaspar_dir, \"files\", \"pfam-DBDs.json\")) as f:\n",
    "    pfam_cutoffs = json.load(f)\n",
    "\n",
    "# Initialize\n",
    "fasta_file = os.path.join(clusters_dir, \"TFs.fasta\" % species_dict[species])\n",
    "\n",
    "if not os.path.exists(\"%s.psq\" % fasta_file):\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "\n",
    "        Jglobals.write(fasta_file, \">%s\\n%s\" % (tf.uniacc, tf.sequence))\n",
    "\n",
    "    # Make BLAST+ database\n",
    "    cmd = \"makeblastdb -in %s -dbtype prot\" % fasta_file\n",
    "    process = subprocess.run([cmd], shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "# Skip if JSON file already exists\n",
    "#json_file = os.path.join(clusters_dir, \"clusters.json\")\n",
    "#if not os.path.exists(json_file):\n",
    "\n",
    "# Start with TFs supported by both in vivo and in vitro evidence\n",
    "for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "\n",
    "    if tf.uniacc in clusters:\n",
    "        continue\n",
    "\n",
    "    if tf.invivo > 0 and tf.invitro > 0:\n",
    "\n",
    "        if tf.gene_name != \"jun-1\":\n",
    "            continue\n",
    "\n",
    "        # Get cluster members\n",
    "        members = get_members(tf)\n",
    "\n",
    "        break\n",
    "\n",
    "        if members:\n",
    "\n",
    "            cluster += 1\n",
    "\n",
    "            for member in members:\n",
    "                clusters.setdefault(member, cluster)\n",
    "\n",
    "# Then focus on TFs supported by one kind of evidence\n",
    "for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "\n",
    "    if tf.uniacc in clusters:\n",
    "        continue\n",
    "\n",
    "    if tf.evidence > 0:\n",
    "\n",
    "        if tf.gene_name != \"jun-1\":\n",
    "            continue\n",
    "\n",
    "        # Get cluster members\n",
    "        members = get_members(tf)\n",
    "\n",
    "        break\n",
    "\n",
    "        if members:\n",
    "\n",
    "            cluster += 1\n",
    "\n",
    "            for member in members:\n",
    "                clusters.setdefault(member, cluster)\n",
    "\n",
    "# Write\n",
    "#Jglobals.write(json_file, json.dumps(clusters, sort_keys=True, indent=4, separators=(\",\", \": \")))\n",
    "\n",
    "with open(json_file) as f:\n",
    "    clusters = json.load(f)\n",
    "\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    if tf.uniacc in clusters:\n",
    "        tf.cluster_num = clusters[tf.uniacc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Output TSV  #\n",
    "#-------------#\n",
    "\n",
    "fields = [\"Gene Name\", \"Species\", \"UniProt Accession\", \"UniProt Entry\", \"Status\", \"Sequence\", \"Family\", \"Cluster\",\n",
    "          \"Evidence\", \"JASPAR\", \"HOCOMOCO\", \"ChIP-Atlas\", \"CistromeDB\", \"GTRD\", \"ReMap\", \"DAP-seq\", \"HT-SELEX\",\n",
    "          \"CIS-BP\", \"UniPROBE\", \"SMiLE-seq\"]\n",
    "Jglobals.write(\"./GRECO.tsv\", \"\\t\".join(fields))\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    Jglobals.write(\"./GRECO.tsv\", tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
