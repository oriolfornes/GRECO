{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ofornes/Work/GRECO/JASPAR-profile-inference',\n",
       " '/home/ofornes/Work/GRECO',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python37.zip',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python3.7',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python3.7/site-packages',\n",
       " '/home/ofornes/Work/Anaconda3/envs/JASPAR-profile-inference/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/ofornes/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append JASPAR-profile-inference to path\n",
    "jaspar_dir = os.path.abspath(\"./JASPAR-profile-inference\")\n",
    "sys.path.insert(0, jaspar_dir)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from JASPAR-profile-inference\n",
    "from __init__ import Jglobals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Class       #\n",
    "#-------------#\n",
    "\n",
    "class TF(object):\n",
    "\n",
    "    def __init__(self, gene_name, species):\n",
    "\n",
    "        self.gene_name = gene_name\n",
    "        self.species = species\n",
    "        self.uniacc = None\n",
    "        self.unientry = None\n",
    "        self.status = None\n",
    "        self.sequence = None\n",
    "        self.family = \"Unknown\"\n",
    "        self.cluster_num = None\n",
    "        # self.orthodb = set()\n",
    "        self.jaspar_id = None\n",
    "        self.hocomoco_id = set()\n",
    "        \n",
    "        # In vivo\n",
    "        self.chip_atlas = set()\n",
    "        self.cistromedb = set()\n",
    "        self.gtrd = set()\n",
    "        self.dap_seq = set()\n",
    "        self.remap = set()\n",
    "\n",
    "        # In vitro\n",
    "        self.ht_selex = set()\n",
    "        self.cisbp = set()\n",
    "        self.uniprobe = set()\n",
    "        self.smile_seq = set()\n",
    "\n",
    "        # Hidden variables (for internal use only)\n",
    "        self._uniaccs = set()\n",
    "        self._unientries = set()\n",
    "        self._sequences = set()\n",
    "\n",
    "    @property\n",
    "    def invivo(self):\n",
    "        \"\"\"\n",
    "        Returns 1 if the TF has been profiled by in vivo methods,\n",
    "        or 0 otherwise.\n",
    "        @rtype = {int}\n",
    "        \"\"\"\n",
    "\n",
    "        # For simplicity, ChIP-seq ~ ChIP-exo ~ DAP-seq\n",
    "        if self.chip_atlas or self.cistromedb or self.gtrd or self.dap_seq or self.remap:\n",
    "            return(1)\n",
    "\n",
    "        return(0)\n",
    "\n",
    "    @property\n",
    "    def invitro(self):\n",
    "        \"\"\"\n",
    "        Returns the number of different experimental methods by\n",
    "        which a TF has been profiled in vitro.\n",
    "        @rtype = {int}\n",
    "        \"\"\"\n",
    "\n",
    "        n = 0\n",
    "\n",
    "        if self.ht_selex:\n",
    "            n += 1\n",
    "        # i.e. PBM\n",
    "        if self.cisbp or self.uniprobe:\n",
    "            n += 1\n",
    "        if self.smile_seq:\n",
    "            n += 1\n",
    "\n",
    "        return(n)\n",
    "\n",
    "    @property\n",
    "    def evidence(self):\n",
    "        \"\"\"\n",
    "        Returns the amount of evidence associated with a TF.\n",
    "        @rtype = {int}\n",
    "        \"\"\"\n",
    "        return(self.invivo+self.invitro)\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        string = \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "            self.gene_name,\n",
    "            self.species,\n",
    "            self.uniacc,\n",
    "            # \";\".join(sorted([i for i in self._uniaccs if i != self.uniacc])),\n",
    "            self.unientry,\n",
    "            # \";\".join(sorted([i for i in self._unientries if i != self.unientry])),\n",
    "            self.status,\n",
    "            self.sequence,\n",
    "            # \";\".join(sorted([i for i in self._sequences if i != self.sequence])),\n",
    "            self.family,\n",
    "            self.cluster_num,\n",
    "            self.evidence,\n",
    "            # \";\".join(sorted([i for i in self._pfam_ids if i != self.pfam_id])),\n",
    "            # \";\".join(sorted(self.orthodb)),\n",
    "            self.jaspar_id,\n",
    "            \";\".join(sorted(self.hocomoco_id)),\n",
    "            \";\".join(sorted(self.chip_atlas)),\n",
    "            \";\".join(sorted(self.cistromedb)),\n",
    "            \";\".join(sorted(self.gtrd)),\n",
    "            \";\".join(sorted(self.remap)),\n",
    "            \";\".join(sorted(self.dap_seq)),\n",
    "            \";\".join(sorted(self.ht_selex)),\n",
    "            \";\".join(sorted(self.cisbp)),\n",
    "            \";\".join(sorted(self.uniprobe)),\n",
    "            \";\".join(sorted(self.smile_seq))\n",
    "        )\n",
    "\n",
    "        return(string)\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        string = \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "            self.gene_name,\n",
    "            self.species,\n",
    "            self.uniacc,\n",
    "            # \";\".join(sorted([i for i in self._uniaccs if i != self.uniacc])),\n",
    "            self.unientry,\n",
    "            # \";\".join(sorted([i for i in self._unientries if i != self.unientry])),\n",
    "            self.status,\n",
    "            self.sequence,\n",
    "            # \";\".join(sorted([i for i in self._sequences if i != self.sequence])),\n",
    "            self.family,\n",
    "            self.cluster_num,\n",
    "            self.evidence,\n",
    "            # \";\".join(sorted([i for i in self._pfam_ids if i != self.pfam_id])),\n",
    "            # \";\".join(sorted(self.orthodb)),\n",
    "            self.jaspar_id,\n",
    "            \";\".join(sorted(self.hocomoco_id)),\n",
    "            \";\".join(sorted(self.chip_atlas)),\n",
    "            \";\".join(sorted(self.cistromedb)),\n",
    "            \";\".join(sorted(self.gtrd)),\n",
    "            \";\".join(sorted(self.remap)),\n",
    "            \";\".join(sorted(self.dap_seq)),\n",
    "            \";\".join(sorted(self.ht_selex)),\n",
    "            \";\".join(sorted(self.cisbp)),\n",
    "            \";\".join(sorted(self.uniprobe)),\n",
    "            \";\".join(sorted(self.smile_seq))\n",
    "        )\n",
    "\n",
    "        return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Paths       #\n",
    "#-------------#\n",
    "\n",
    "hocomoco_file = \"./Data/Databases/HOCOMOCO/HOCOMOCOv11_full_jaspar_format.txt\"\n",
    "chip_atlas_file = \"./Data/Experiments/ChIP-seq.ChIP-Atlas.tsv\"\n",
    "cistromedb_file = \"./Data/Experiments/ChIP-seq.CistromeDB.tsv\"\n",
    "gtrd_file = \"./Data/Experiments/ChIP-seq.GTRD.tsv\"\n",
    "remap_file = \"./Data/Experiments/ChIP-seq.ReMap2020.tsv\"\n",
    "dap_seq_file = \"./Data/Experiments/DAP-seq.PMID:27203113.tsv\"\n",
    "ht_selex_files = [\"./Data/Experiments/HT-SELEX.PMID:23332764.tsv\",\n",
    "                  \"./Data/Experiments/HT-SELEX.PMID:28473536.tsv\"]\n",
    "cisbp_txt_file = \"./Data/Databases/CisBP-2.0/PWMs.txt\"\n",
    "cisbp_tsv_file = \"./Data/Experiments/PBM.CisBP-2.0.tsv\"\n",
    "uniprobe_file = \"./Data/Experiments/PBM.UniPROBE.tsv\"\n",
    "smile_seq = \"./Data/Experiments/SMiLE-seq.PMID:28092692.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At1g23810\tArabidopsis thaliana\tQ9ZUB5\tQ9ZUB5_ARATH\tUnreviewed\tMAGGSKSPASSLEDGKAYVNAVKVALEEAEPAKYQEFLRLFHEVIARRMGMATFSARMQDLLKDHPSLCLGLNVMLAPEYQRAIPPEASEEFHKVVGRSVPRPEPTIDDATSYLIAVKEAFHDEPAKYEEMLKLLNDFKARRVNAASVIARVEELMKDHSNLLFGFCVFLSATTSFTTKLKAKFQGDGSQVVDSVLQIMRMYGEGNKSKHDAYQEIVALVQGHDDLVMELSQIFTDPSTRV\tUnknown\tNone\t0\tnan\t\t\t\t\t\t\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "#-------------#\n",
    "# Parse Data  #\n",
    "#-------------#\n",
    "\n",
    "# Initialize\n",
    "tfs = set()\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(\"./Data/Parsed/TFs.tab.gz\"):\n",
    "\n",
    "    # Initialize\n",
    "    tf = TF(line[0], line[1])\n",
    "\n",
    "    # Get UniProt Accession\n",
    "    uniaccs = line[2].split(\";\")\n",
    "    tf.uniacc = uniaccs[0]\n",
    "    tf._uniaccs.update(set(uniaccs))\n",
    "\n",
    "    # Get UniProt Entry\n",
    "    unientries = line[3].split(\";\")\n",
    "    tf.unientry = unientries[0]\n",
    "    tf._unientries.update(set(unientries))\n",
    "\n",
    "    # Get sequence\n",
    "    sequences = line[4].split(\";\")\n",
    "    tf.sequence = sequences[0]\n",
    "    tf._sequences.update(set(sequences))\n",
    "\n",
    "    # Get status (i.e. reviewed or not)\n",
    "    tf.status = line[5]\n",
    "\n",
    "    # Get family\n",
    "    tf.family = line[6]\n",
    "\n",
    "    # Get JASPAR ids\n",
    "    tf.jaspar_id = line[7]\n",
    "\n",
    "    # # Get orthoDB cluster\n",
    "    # codec = coreapi.codecs.CoreJSONCodec()\n",
    "    # for uniacc in tf._uniaccs:\n",
    "    #     json_file = os.path.join(args.orthodb, \"%s.json\" % uniacc)\n",
    "    #     if not os.path.exists(json_file):\n",
    "    #         client = coreapi.Client()\n",
    "    #         response = client.get(\n",
    "    #             \"https://www.orthodb.org/search?query=%s&level=2759&species=2759\" % uniacc)\n",
    "    #         json_obj = json.loads(codec.encode(response))\n",
    "    #         with open(json_file, \"w\") as j:\n",
    "    #             j.write(json.dumps(json_obj, sort_keys=True, indent=4, separators=(\",\", \": \")))\n",
    "    #     with open(json_file, \"r\") as j:  \n",
    "    #         json_obj = json.load(j)\n",
    "    #         for orthodb in json_obj[\"data\"]:\n",
    "    #             tf.orthodb.add(orthodb)\n",
    "\n",
    "    # Add TF to TFs\n",
    "    tfs.add(tf)\n",
    "\n",
    "print(next(iter(tfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# HOCOMOCO    #\n",
    "#-------------#\n",
    "\n",
    "#  678 Homo sapiens\n",
    "#  451 Mus musculus\n",
    "\n",
    "# SMCA5_MOUSE # Not a TF: SWI/SNF-related matrix-associated actin-dependent regulator of chromatin subfamily A member 5\n",
    "# FUBP1_MOUSE # Not a TF: Far upstream element-binding protein 1\n",
    "# BRCA1_MOUSE # Not a TF: Breast cancer type 1 susceptibility protein homolog\n",
    "# EVI1_MOUSE  # Not a TF: Histone-lysine N-methyltransferase MECOM\n",
    "# TAF1_MOUSE  # Not a TF: Transcription initiation factor TFIID subunit 1\n",
    "# BRAC_MOUSE  # Not a valid UniProt Entry\n",
    "# HLTF_MOUSE  # Not a TF: Helicase-like transcription factor\n",
    "# TAF1_HUMAN  # Not a TF: Transcription initiation factor TFIID subunit 1\n",
    "# HLTF_HUMAN  # Not a TF: Helicase-like transcription factor\n",
    "# BRCA1_HUMAN # Not a TF: Breast cancer type 1 susceptibility protein\n",
    "# SMCA5_HUMAN # Not a TF: SWI/SNF-related matrix-associated actin-dependent regulator of chromatin subfamily A member 5\n",
    "# ZF64A_HUMAN # Not a valid UniProt Entry\n",
    "# BRAC_HUMAN  # Not a valid UniProt Entry\n",
    "# EVI1_HUMAN  # Not a TF: Histone-lysine N-methyltransferase MECOM\n",
    "# FUBP1_HUMAN # Not a TF: Far upstream element-binding protein 1\n",
    "# BPTF_HUMAN  # Not a TF: Nucleosome-remodeling factor subunit BPTF\n",
    "# CENPB_HUMAN # Not a TF: Major centromere autoantigen B\n",
    "# ZBT48_HUMAN # Not a valid UniProt Entry; should be TZAP_HUMAN\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_file(hocomoco_file):\n",
    "\n",
    "    if line.startswith(\">\"):\n",
    "\n",
    "        # Get unientry\n",
    "        m = re.search(\"(\\w+_(HUMAN|MOUSE))\", line)\n",
    "        unientry = m.group(1)\n",
    "\n",
    "        # For each TF...\n",
    "        for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "            if unientry in tf._unientries:\n",
    "                tf.hocomoco_id.add(line[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHR {'AHR_HUMAN.H11MO.0.B'}\n",
      "AIRE {'AIRE_HUMAN.H11MO.0.C'}\n",
      "ALX1 {'ALX1_HUMAN.H11MO.0.B'}\n",
      "ALX3 {'ALX3_HUMAN.H11MO.0.D'}\n",
      "ALX4 {'ALX4_HUMAN.H11MO.0.D'}\n",
      "AR {'ANDR_HUMAN.H11MO.0.A', 'ANDR_HUMAN.H11MO.1.A', 'ANDR_HUMAN.H11MO.2.A'}\n",
      "ARID3A {'ARI3A_HUMAN.H11MO.0.D'}\n",
      "ARID5B {'ARI5B_HUMAN.H11MO.0.C'}\n",
      "ARNT {'ARNT_HUMAN.H11MO.0.B'}\n",
      "ARNT2 {'ARNT2_HUMAN.H11MO.0.D'}\n",
      "...\n",
      "//\n",
      "Total genes: 1057\n",
      "Total feats: 1214\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.hocomoco_id)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.hocomoco_id)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# GTRD        #\n",
    "#-------------#\n",
    "\n",
    "#   71 Arabidopsis thaliana\n",
    "#  213 Caenorhabditis elegans\n",
    "#   11 Danio rerio\n",
    "#  249 Drosophila melanogaster\n",
    "# 1236 Homo sapiens\n",
    "#  513 Mus musculus\n",
    "#   12 Rattus norvegicus\n",
    "#  137 Saccharomyces cerevisiae\n",
    "#   32 Schizosaccharomyces pombe\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(gtrd_file):\n",
    "\n",
    "    # Inialize\n",
    "    experiment_id = line[0]\n",
    "    uniacc = line[1]\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "        if uniacc in tf._uniaccs:\n",
    "            tf.gtrd.add(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11723 {'EXP043557'}\n",
      "ABF4 {'EXP041418'}\n",
      "ADD1 {'EXP044073'}\n",
      "ADNP {'EXP039553'}\n",
      "AEBP2 {'EXP040109'}\n",
      "AGL8 {'EXP040838'}\n",
      "AP1 {'EXP041282'}\n",
      "AR {'EXP038636', 'EXP038189', 'EXP040661', 'EXP038106', 'EXP040665', 'EXP038192', 'EXP038188', 'EXP038193', 'EXP037263', 'EXP040660', 'EXP038191', 'EXP036887', 'EXP037067'}\n",
      "ARF6 {'EXP041307'}\n",
      "ARID2 {'EXP040161'}\n",
      "...\n",
      "//\n",
      "Total genes: 814\n",
      "Total feats: 1958\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.gtrd)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.gtrd)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# DAP-seq     #\n",
    "#-------------#\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(dap_seq_file):\n",
    "\n",
    "    if line[0] == \"AvgSpotLen\":\n",
    "        continue\n",
    "\n",
    "    species = line[8]\n",
    "    sra_run = line[9]\n",
    "    gene = line[15]\n",
    "\n",
    "    if line[8] not in species:\n",
    "        continue\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "        if gene.upper() in tf.gene_name.upper():\n",
    "            tf.dap_seq.add(sra_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABF2 {'SRR2926839'}\n",
      "ABF2 {'SRR2926839'}\n",
      "ABI5 {'SRR2926840', 'SRR2926841'}\n",
      "ABR1 {'SRR2926082', 'SRR2926081'}\n",
      "AGL13 {'SRR2926463'}\n",
      "AGL15 {'SRR2926465', 'SRR2926464'}\n",
      "AGL16 {'SRR2926466', 'SRR2926467'}\n",
      "AGL42 {'SRR2926470'}\n",
      "AGL6 {'SRR2926472'}\n",
      "AGL61 {'SRR2926472'}\n",
      "...\n",
      "//\n",
      "Total genes: 474\n",
      "Total feats: 911\n"
     ]
    }
   ],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.dap_seq)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.dap_seq)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# HT-SELEX    #\n",
    "#-------------#\n",
    "\n",
    "# For each file...\n",
    "for file_name in ht_selex_files:\n",
    "\n",
    "    m = re.search(\"HT-SELEX.PMID:(\\d+).tsv\", file_name)\n",
    "    pmid = int(m.group(1))\n",
    "\n",
    "    # For each line...\n",
    "    for line in Jglobals.parse_tsv_file(file_name):\n",
    "\n",
    "        if line[0] == \"Alias\":\n",
    "            continue\n",
    "\n",
    "        m = re.search(\"^([A-Za-z\\d]+)_\", line[0])\n",
    "        if m:\n",
    "\n",
    "            gene_name = m.group(1)\n",
    "\n",
    "            if pmid == 23332764:\n",
    "                sra_run = line[14]\n",
    "            else:\n",
    "                sra_run = line[19]\n",
    "\n",
    "            # For each TF...\n",
    "            for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "                # HT-SELEX data only available for human and mouse\n",
    "                if tf.species not in [\"Homo sapiens\", \"Mus musculus\"]:\n",
    "                    continue\n",
    "                if tf.gene_name == gene_name:\n",
    "                    tf.ht_selex.add(sra_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.ht_selex)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.ht_selex)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# CIS-BP      #\n",
    "#-------------#\n",
    "\n",
    "valid_matrix_ids = set()\n",
    "\n",
    "# Get valid PWMs\n",
    "for matrix_id in Jglobals.parse_file(cisbp_txt_file):\n",
    "    valid_matrix_ids.add(matrix_id)\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_file(cisbp_tsv_file):\n",
    "\n",
    "    matrix_ids = re.findall(\"(M\\d{5}_2.00)\", line)\n",
    "\n",
    "    if matrix_ids:\n",
    "\n",
    "        line = line.strip(\"\\n\").split(\"\\t\")\n",
    "        gene_name = line[1]\n",
    "        species = line[2].replace(\"_\", \" \")\n",
    "\n",
    "        # Skip inferred TFs\n",
    "        if line[3] != \"D\":\n",
    "            continue\n",
    "\n",
    "        # For each TF...\n",
    "        for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "            if tf.gene_name.upper() == gene_name.upper() and species == tf.species:\n",
    "                tf.cisbp.update(valid_matrix_ids.intersection(set(matrix_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.cisbp)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.cisbp)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# UniPROBE    #\n",
    "#-------------#\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(uniprobe_file):\n",
    "   \n",
    "    if line[0] == \"Protein\":\n",
    "        continue\n",
    "\n",
    "    gene_name = line[0]\n",
    "    uniprobe_id = line[1]\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "        if tf.gene_name.upper() == gene_name.upper() and line[2] == tf.species:\n",
    "            tf.uniprobe.add(uniprobe_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.uniprobe)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.uniprobe)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# SMiLE-seq   #\n",
    "#-------------#\n",
    "\n",
    "synonyms = {\n",
    "    \"CEBPb\": \"CEBPB\",\n",
    "    \"cFOS\": \"FOS\",\n",
    "    \"cFOSL2\": \"FOSL2\",\n",
    "    \"cJUN\": \"JUN\",\n",
    "    \"PPARa\": \"PPARA\",\n",
    "    \"PPARg\": \"PPARG\",\n",
    "    \"RXRa\": \"RXRA\",\n",
    "    \"RXRg\": \"RXRG\"            \n",
    "}\n",
    "\n",
    "# For each line...\n",
    "for line in Jglobals.parse_tsv_file(smile_seq):\n",
    "\n",
    "    if line[0] == \"Assay_Type\":\n",
    "        continue\n",
    "\n",
    "    sra_run = line[13]\n",
    "\n",
    "    for gene_name in line[16].split(\"_\")[0].split(\"-\"):\n",
    "        if gene_name in synonyms:\n",
    "            gene_name = synonyms[gene_name]\n",
    "\n",
    "        # For each TF...\n",
    "        for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "            if tf.gene_name.upper() == gene_name.upper() and line[12] == tf.species:\n",
    "                tf.smile_seq.add(sra_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = 0\n",
    "feats = 0\n",
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "    subtotal_feats = len(tf.smile_seq)\n",
    "    if subtotal_feats > 0:\n",
    "        genes += 1\n",
    "        feats += subtotal_feats\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.smile_seq)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "print(\"Total genes: %s\" % genes)\n",
    "print(\"Total feats: %s\" % feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Triples     #\n",
    "#-------------#\n",
    "count = 0\n",
    "evidence = {}\n",
    "for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "    if tf.invivo > 0 and tf.invitro > 1:\n",
    "        evidence.setdefault(tf.species, 0)\n",
    "        evidence[tf.species] += 1\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.species, tf.evidence, tf.invivo, tf.invitro)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "for species in sorted(evidence):\n",
    "    print(species, evidence[species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Duos        #\n",
    "#-------------#\n",
    "count = 0\n",
    "evidence = {}\n",
    "for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "    if tf.invivo > 0 and tf.invitro > 0:\n",
    "        evidence.setdefault(tf.species, 0)\n",
    "        evidence[tf.species] += 1\n",
    "        if count < 10:\n",
    "            print(tf.gene_name, tf.species, tf.evidence, tf.invivo, tf.invitro)\n",
    "        elif count == 10:\n",
    "            print(\"...\")\n",
    "        else:\n",
    "            pass\n",
    "        count += 1\n",
    "print(\"//\")\n",
    "for species in sorted(evidence):\n",
    "    print(species, evidence[species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Pfam        #\n",
    "#-------------#\n",
    "\n",
    "# The following code is adapted from:\n",
    "# https://github.com/wassermanlab/JASPAR-profile-inference/blob/master/files/get_files.py\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "import json\n",
    "from infer_profile import hmmAlign, hmmScan, _makeSeqFile\n",
    "\n",
    "# Initialize\n",
    "seq_file = \".seq.fasta\"\n",
    "hmm_database = os.path.join(jaspar_dir, \"files\", \"pfam-DBDs\", \"all_DBDs.hmm\")\n",
    "\n",
    "# Change dir\n",
    "os.chdir(sys.path[1])\n",
    "os.chdir(os.path.abspath(\"./Data/Pfam/\"))\n",
    "\n",
    "# Skip if JSON file already exists\n",
    "json_file = \"TFs.json\"\n",
    "if not os.path.exists(json_file):\n",
    "\n",
    "    # Initialize\n",
    "    pfams = {}\n",
    "\n",
    "    # For each TF...\n",
    "    for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "\n",
    "        # Initialize\n",
    "        uniacc = tf.uniacc\n",
    "        pfams.setdefault(uniacc, [])\n",
    "\n",
    "        # Make seq file\n",
    "        seq = Seq(tf.sequence, IUPAC.protein)\n",
    "        seq_record = SeqRecord(seq, id=uniacc, name=uniacc, description=uniacc)\n",
    "        _makeSeqFile(seq_record, seq_file)\n",
    "\n",
    "        # For each DBD...\n",
    "        for pfam_ac, start, end, evalue in hmmScan(seq_file, hmm_database, non_overlapping_domains=True):\n",
    "\n",
    "            # Initialize\n",
    "            hmm_file = os.path.join(jaspar_dir, \"files\", \"pfam-DBDs\", \"%s.hmm\" % pfam_ac)\n",
    "\n",
    "            # Make seq file\n",
    "            sub_seq = seq[start:end]\n",
    "            seq_record = SeqRecord(sub_seq, id=uniacc, name=uniacc, description=uniacc)\n",
    "            _makeSeqFile(seq_record, seq_file)\n",
    "\n",
    "            # Add DBDs\n",
    "            alignment = hmmAlign(seq_file, hmm_file)\n",
    "            pfams[uniacc].append((pfam_ac, alignment, start+1, end, evalue))\n",
    "\n",
    "    # Write\n",
    "    Jglobals.write(json_file, json.dumps(pfams, sort_keys=True, indent=4, separators=(\",\", \": \")))\n",
    "\n",
    "    # Remove seq file\n",
    "    if os.path.exists(seq_file):\n",
    "        os.remove(seq_file)\n",
    "\n",
    "# Change dir back\n",
    "os.chdir(sys.path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------#\n",
    "# Cluster     #\n",
    "#-------------#\n",
    "\n",
    "# The following code is adapted from:\n",
    "# https://github.com/wassermanlab/JASPAR-profile-inference/blob/master/finfer_profile.py\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from infer_profile import _fetchXs, _filter_results_by_Rost, _removeLowercase\n",
    "\n",
    "def get_members(tf):\n",
    "\n",
    "    # Initialize\n",
    "    members = []\n",
    "    tf_DBDs = [dbd[0] for dbd in pfams[tf.uniacc]]\n",
    "    tf_alignments = [dbd[1] for dbd in pfams[tf.uniacc]]\n",
    "    seq = Seq(tf.sequence, IUPAC.protein)\n",
    "    seq_record = SeqRecord(seq, id=tf.uniacc, name=tf.uniacc, description=tf.uniacc)\n",
    "    fasta_file = os.path.join(clusters_dir, \"%s.fasta\" % species_dict[tf.species])\n",
    "\n",
    "    # Get cut-offs on the percentage of sequence identity\n",
    "    cutoffs = {}\n",
    "    for pfam_ac in pfam_cutoffs:\n",
    "        if pfam_cutoffs[pfam_ac][0] in tf_DBDs:\n",
    "            cutoffs.setdefault(pfam_cutoffs[pfam_ac][0], pfam_cutoffs[pfam_ac][1])\n",
    "\n",
    "    # BLAST+ search\n",
    "    blast_results = BLAST(seq_record, fasta_file)\n",
    "\n",
    "    # Filter results\n",
    "    for filtered_result in sorted(_filter_results_by_Rost(blast_results), key=lambda x: x[5], reverse=True):\n",
    "\n",
    "        if filtered_result[1] in clusters:\n",
    "            continue\n",
    "\n",
    "        # Both TFs have same DBD composition\n",
    "        if [dbd[0] for dbd in pfams[filtered_result[1]]] == tf_DBDs:\n",
    "\n",
    "            # Inference: percentage of sequence identity\n",
    "            pids = []\n",
    "            pid_cutoffs = []\n",
    "            alignments = [dbd[1] for dbd in pfams[filtered_result[1]]]\n",
    "            for a in range(len(alignments)):\n",
    "                s1 = _removeLowercase(tf_alignments[a])\n",
    "                s2 = _removeLowercase(alignments[a])\n",
    "                pids.append(sum(_fetchXs(s1, s2))/float(len(s1)))\n",
    "                pid_cutoffs.append(pids[-1] >= cutoffs[tf_DBDs[a]])\n",
    "            if True in pid_cutoffs:\n",
    "                members.append(filtered_result[1])\n",
    "\n",
    "    return(members)\n",
    "\n",
    "def BLAST(seq_record, fasta_file):\n",
    "\n",
    "    # Initialize\n",
    "    blast_results = set()\n",
    "    outfmt = \"sseqid pident length qstart qend sstart send evalue bitscore ppos qlen slen\"\n",
    "\n",
    "    # Run BLAST+\n",
    "    cmd = \"blastp -db %s -outfmt \\\"6 %s\\\"\" % (fasta_file, outfmt)\n",
    "    process = subprocess.Popen([cmd], shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    fasta_sequence = \">%s\\n%s\" % (seq_record.id, seq_record.seq)\n",
    "    process.stdin.write(fasta_sequence.encode())\n",
    "    (blast_records, blast_errors) = process.communicate()\n",
    "\n",
    "    # For each BLAST+ record...\n",
    "    for blast_record in blast_records.decode(\"utf-8\").split(\"\\n\"):\n",
    "\n",
    "        # Custom BLAST+ record:\n",
    "        # (1) identifier of target sequence;\n",
    "        # (2) percentage of identical matches;\n",
    "        # (3) alignment length;\n",
    "        # (4-5, 6-7) start and end-position in query and in target;\n",
    "        # (8) E-value;\n",
    "        # (9) bit score;\n",
    "        # (10) percentage of positive-scoring matches; and\n",
    "        # (4-7, 11, 12) joint coverage (i.e. square root of the coverage\n",
    "        # on the query and the target).\n",
    "        blast_record = blast_record.split(\"\\t\")\n",
    "\n",
    "        # Skip if not a BLAST+ record\n",
    "        if len(blast_record) != 12: continue\n",
    "\n",
    "        # Get BLAST+ record\n",
    "        target_id = blast_record[0]\n",
    "        percent_identities = float(blast_record[1])\n",
    "        alignment_length = int(blast_record[2])\n",
    "        query_start_end = \"%s-%s\" % (blast_record[3], blast_record[4])\n",
    "        target_start_end = \"%s-%s\" % (blast_record[5], blast_record[6])\n",
    "        e_value = float(blast_record[7])\n",
    "        score = float(blast_record[8])\n",
    "        percent_similarity = float(blast_record[9])\n",
    "        query_aligned_residues = int(blast_record[4]) - int(blast_record[3]) + 1\n",
    "        query_length = float(blast_record[10])\n",
    "        target_aligned_residues = int(blast_record[6]) - int(blast_record[5]) + 1\n",
    "        target_length = float(blast_record[11])\n",
    "        query_coverage = query_aligned_residues * 100 / query_length\n",
    "        target_coverage = target_aligned_residues * 100 / target_length\n",
    "        joint_coverage = math.sqrt(query_coverage * target_coverage)\n",
    "\n",
    "        # Add BLAST+ record to search results\n",
    "        blast_results.add((seq_record.id, target_id, query_start_end, target_start_end, e_value, score, percent_identities, alignment_length, percent_similarity, joint_coverage))\n",
    "\n",
    "    # Return results sorted by score\n",
    "    return(list(sorted(blast_results, key=lambda x: x[-1], reverse=True)))\n",
    "\n",
    "# Initialize\n",
    "cluster = 0\n",
    "clusters = {}\n",
    "clusters_dir = \"./Data/Clusters/\"\n",
    "species_dict = {\n",
    "    \"Arabidopsis thaliana\": \"plants\",\n",
    "    \"Caenorhabditis elegans\": \"nematodes\",\n",
    "    \"Drosophila melanogaster\": \"insects\",\n",
    "    \"Homo sapiens\": \"vertebrates\",\n",
    "    \"Mus musculus\": \"vertebrates\",\n",
    "    \"Saccharomyces cerevisiae\": \"fungi\"\n",
    "}\n",
    "with open(\"./Data/Pfam/TFs.json\") as f:\n",
    "    pfams = json.load(f)\n",
    "with open(os.path.join(jaspar_dir, \"files\", \"pfam-DBDs.json\")) as f:\n",
    "    pfam_cutoffs = json.load(f)\n",
    "\n",
    "for species in species_dict:\n",
    "\n",
    "    # Initialize\n",
    "    fasta_file = os.path.join(clusters_dir, \"%s.fasta\" % species_dict[species])\n",
    "\n",
    "    if not os.path.exists(\"%s.psq\" % fasta_file):\n",
    "\n",
    "        # For each TF...\n",
    "        for tf in sorted(tfs, key=lambda x: x.gene_name):\n",
    "\n",
    "            if tf.species != species:\n",
    "                continue\n",
    "\n",
    "            Jglobals.write(fasta_file, \">%s\\n%s\" % (tf.uniacc, tf.sequence))\n",
    "\n",
    "for species in species_dict:\n",
    "\n",
    "    # Initialize\n",
    "    fasta_file = os.path.join(clusters_dir, \"%s.fasta\" % species_dict[species])\n",
    "\n",
    "    if not os.path.exists(\"%s.psq\" % fasta_file):\n",
    "\n",
    "        # Make BLAST+ database\n",
    "        cmd = \"makeblastdb -in %s -dbtype prot\" % fasta_file\n",
    "        process = subprocess.run([cmd], shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "# Skip if JSON file already exists\n",
    "json_file = os.path.join(clusters_dir, \"clusters.json\")\n",
    "if not os.path.exists(json_file):\n",
    "\n",
    "    # Start with TFs supported by both in vivo and in vitro evidence\n",
    "    for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "\n",
    "        if tf.uniacc in clusters:\n",
    "            continue\n",
    "\n",
    "        if tf.invivo > 0 and tf.invitro > 0:\n",
    "\n",
    "            # Get cluster members\n",
    "            members = get_members(tf)\n",
    "\n",
    "            if members:\n",
    "\n",
    "                cluster += 1\n",
    "\n",
    "                for member in members:\n",
    "                    clusters.setdefault(member, cluster)\n",
    "\n",
    "    # Then focus on TFs supported by one kind of evidence\n",
    "    for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "\n",
    "        if tf.uniacc in clusters:\n",
    "            continue\n",
    "\n",
    "        if tf.evidence > 0:\n",
    "\n",
    "            # Get cluster members\n",
    "            members = get_members(tf)\n",
    "\n",
    "            if members:\n",
    "\n",
    "                cluster += 1\n",
    "\n",
    "                for member in members:\n",
    "                    clusters.setdefault(member, cluster)\n",
    "\n",
    "    # Write\n",
    "    Jglobals.write(json_file, json.dumps(clusters, sort_keys=True, indent=4, separators=(\",\", \": \")))\n",
    "\n",
    "with open(json_file) as f:\n",
    "    clusters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for tf in sorted(tfs, key=lambda x: x.evidence, reverse=True):\n",
    "    if count < 10:\n",
    "        print(tf)\n",
    "    elif count == 10:\n",
    "        print(\"...\")\n",
    "    else:\n",
    "        pass\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
